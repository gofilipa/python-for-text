{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb1a6d0",
   "metadata": {},
   "source": [
    "# machine learning\n",
    "\n",
    "Machine Learning (ML) is a broad topic in Artificial Intelligence (AI)\n",
    "that contains process in natural language (NLP), computer vision,\n",
    "speech recognition, and more. In this workshop, we are going to focus\n",
    "on ML methods for NLP, specifically for text generation. \n",
    "\n",
    "Before moving to text generation, however, it's useful to get a sense\n",
    "of how this process works under the hood. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41bea1",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "\n",
    "How does a text generation tool like ChatGPT work? How does it know\n",
    "what to respond when someone asks it a question? More specifically,\n",
    "how does it know what language to generate, what words follow other\n",
    "words?\n",
    "\n",
    "The answer is that it learns by prediction. It processes massive\n",
    "amounts of text, and from that processing, it gleans a sense of what\n",
    "words tend to follow other words.\n",
    "\n",
    "This is all possible thanks to \"word vectors,\" which is language in a\n",
    "quantified form. Technically speaking, word vectors are representations of words in\n",
    "graphical space. Each word is represented by a series of numbers that\n",
    "together make up its coordinate on a graph. Practically, each of those numbers consists of a list of\n",
    "probabilities, which represent it's relationship to another word in\n",
    "the database.\n",
    "\n",
    "A vector for the words \"cat\" and \"dog\", must look like the following:\n",
    "\n",
    "| word | tiger | cute | bones | wolf  |\n",
    "|---|---|---|---|---|\n",
    "| cat | .90 | .99 | .40 | .35 |\n",
    "| dog | .35 | .99 | .85 | .90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146de6bf",
   "metadata": {},
   "source": [
    "Use the code below to explore word vectors using the `gensim` library and a datast from twitter, `glove-twitter-25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9586893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a527a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.5% 23.6/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.2% 51.6/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 71.9% 75.4/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 86.3% 90.5/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509a8fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.9371739029884338),\n",
       " ('mother', 0.9214695692062378),\n",
       " ('whose', 0.917497456073761),\n",
       " ('called', 0.9146499633789062),\n",
       " ('person', 0.913553774356842),\n",
       " ('wife', 0.9088310599327087),\n",
       " ('being', 0.9037442803382874),\n",
       " ('father', 0.9028053283691406),\n",
       " ('guy', 0.9026350975036621),\n",
       " ('known', 0.8997253179550171)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14d5483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 0.9065622687339783),\n",
       " ('i', 0.8880172371864319),\n",
       " ('he', 0.887438178062439),\n",
       " ('bad', 0.8846145272254944),\n",
       " ('even', 0.8832387924194336),\n",
       " ('be', 0.8784030079841614),\n",
       " ('we', 0.8764979243278503),\n",
       " ('not', 0.8764553666114807),\n",
       " ('had', 0.8762108683586121),\n",
       " ('glad', 0.8758710622787476)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2880439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('protests', 0.9241024851799011),\n",
       " ('forces', 0.9001613259315491),\n",
       " ('afghanistan', 0.8905416131019592),\n",
       " ('activists', 0.8872407078742981),\n",
       " ('troops', 0.880148708820343),\n",
       " ('protesters', 0.8785053491592407),\n",
       " ('violence', 0.8769642114639282),\n",
       " ('parliament', 0.8767853379249573),\n",
       " ('prison', 0.8743768930435181),\n",
       " ('opposition', 0.8693628311157227)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('protest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3cade14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cornell', 0.8837954998016357),\n",
       " ('warren', 0.872944712638855),\n",
       " ('emory', 0.8666537404060364),\n",
       " ('quincy', 0.863002359867096),\n",
       " ('dudley', 0.8600769639015198),\n",
       " ('dayton', 0.8584739565849304),\n",
       " ('carson', 0.8520109057426453),\n",
       " ('savannah', 0.8516344428062439),\n",
       " ('pearson', 0.8490176200866699),\n",
       " ('trump', 0.8488551378250122)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('princeton')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96155cb1",
   "metadata": {},
   "source": [
    "## king - man + woman = queen\n",
    "Why do this to words? Why represent them as numbers? So we can do\n",
    "math! We can do things like linear algebra. This allows us to\n",
    "calculate what words have similar meanings based on how close they are\n",
    "to each other in graphical space. For example, we can do cosine\n",
    "similarity, finding out what two vectors are similar to each other in\n",
    "shape/direction actually gives us a sense of their semantic\n",
    "similarity. Word Vectors open up a world of algebra, calculus, that we\n",
    "can do with language.\n",
    "\n",
    "There's a famous formula that represents this concept. \n",
    "\n",
    "```\n",
    "vector(”King”) - vector(”Man”) + vector(”Woman”) = vector(\"Queen\")\n",
    "```\n",
    "\n",
    "This formular becomes a bit more interesting when we realize that this is the\n",
    "formula that introduced the power of word vectors to the world (see the famous paper\n",
    "[Word2Vec](https://arxiv.org/abs/1301.3781)). So the\n",
    "assumptions it plays on must be deeply embedded across society.œ What exactly is being calculated when we subtract \"man\" and add\n",
    "\"woman\"? What are the implied assumptions about gender here?\n",
    "\n",
    "Learn more about word vectors in the excellent\n",
    "[explanation by Jay\n",
    "Alammar](http://jalammar.github.io/illustrated-word2vec/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7299f",
   "metadata": {},
   "source": [
    "## Attention Mechanism\n",
    "\n",
    "After word vectors, the second big development is the \"*Attention\n",
    "mechanim*\". \n",
    "\n",
    "Attention is a key component of the \"transformer\" model architecture,\n",
    "which was developed in 2017/2018. See the [Attention Is All You\n",
    "Need](https://arxiv.org/abs/1706.03762) paper that introduced the concept. \n",
    "\n",
    "Attention means that context matters, it is taken as input to the\n",
    "calculations. Before attention, neural networks only took into account\n",
    "the words preceding a given word. By contrast, With attention, networks\n",
    "could take the context, the words that surround a word, into their\n",
    "calculations. \n",
    "\n",
    "Transformer architecture was introduced in the BERT model, which\n",
    "stands for *Bidirectional Encoder Representations from\n",
    "Transformers*. Developed by Google, BERT is the first generation\n",
    "Transformer model which, released on an open-source on *Apache 2.0 license*, one of\n",
    "most permissive licenses, which inspired many descendants that are\n",
    "still popular today.\n",
    "\n",
    "When we move to the 🤗 website, we will see firsthand *many*\n",
    "variations of BERT, the berts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa1735",
   "metadata": {},
   "source": [
    "## Training and Fine-Tuning\n",
    "\n",
    "The \"berts\" are what I call the models that have been trained and/or\n",
    "fine-tuned on the original BERT base model. \n",
    "\n",
    "What is the *difference between training and fine-tuning*?\n",
    "- training is the creation of a \"base\" model. It requires lots, LOTS\n",
    "    of data, gigabites of data, and compute power. It takes weeks,\n",
    "    sometimes longer.\n",
    "- fine-tuning is taking a base model, which has already been trained\n",
    "    (like BERT) and training it further, with a much smaller dataset\n",
    "    that is focused on a specific topic. It involves customizing the\n",
    "    model to work for a particular topic or kind of data.\n",
    "    - finBERT for sentiment analysis of financial data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb636d",
   "metadata": {},
   "source": [
    "## Why am I saying all this? \n",
    "\n",
    "To de-mystify the tool. These tools are not magic, they are not\n",
    "    intuitive, possibly not even \"intelligent\", they can just do a lot\n",
    "    of math.\n",
    "\n",
    "Also, to understand variations in models and performance. Because we\n",
    "    are going to engage with different language models in this\n",
    "    workshop, in all shapes and sizes, and you'll see some of these\n",
    "    tools acting differently than what you're used to with chatgpt, or\n",
    "    more polished AI applications. It helps to know how a bit about\n",
    "    how they work and their major developments to understand this ever\n",
    "    more complicated ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104e3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

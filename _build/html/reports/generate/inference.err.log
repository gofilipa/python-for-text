Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 173, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "/opt/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/anaconda3/lib/python3.11/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from transformers import pipeline

pipe = pipeline("text-generation", model="EleutherAI/gpt-neo-125m")
------------------

----- stderr -----
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[2], line 3[0m
[1;32m      1[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtransformers[39;00m [38;5;28;01mimport[39;00m pipeline
[0;32m----> 3[0m pipe [38;5;241m=[39m pipeline([38;5;124m"[39m[38;5;124mtext-generation[39m[38;5;124m"[39m, model[38;5;241m=[39m[38;5;124m"[39m[38;5;124mEleutherAI/gpt-neo-125m[39m[38;5;124m"[39m)

File [0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/__init__.py:906[0m, in [0;36mpipeline[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)[0m
[1;32m    904[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(model, [38;5;28mstr[39m) [38;5;129;01mor[39;00m framework [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[1;32m    905[0m     model_classes [38;5;241m=[39m {[38;5;124m"[39m[38;5;124mtf[39m[38;5;124m"[39m: targeted_task[[38;5;124m"[39m[38;5;124mtf[39m[38;5;124m"[39m], [38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m: targeted_task[[38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m]}
[0;32m--> 906[0m     framework, model [38;5;241m=[39m infer_framework_load_model(
[1;32m    907[0m         model,
[1;32m    908[0m         model_classes[38;5;241m=[39mmodel_classes,
[1;32m    909[0m         config[38;5;241m=[39mconfig,
[1;32m    910[0m         framework[38;5;241m=[39mframework,
[1;32m    911[0m         task[38;5;241m=[39mtask,
[1;32m    912[0m         [38;5;241m*[39m[38;5;241m*[39mhub_kwargs,
[1;32m    913[0m         [38;5;241m*[39m[38;5;241m*[39mmodel_kwargs,
[1;32m    914[0m     )
[1;32m    916[0m model_config [38;5;241m=[39m model[38;5;241m.[39mconfig
[1;32m    917[0m hub_kwargs[[38;5;124m"[39m[38;5;124m_commit_hash[39m[38;5;124m"[39m] [38;5;241m=[39m model[38;5;241m.[39mconfig[38;5;241m.[39m_commit_hash

File [0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:234[0m, in [0;36minfer_framework_load_model[0;34m(model, config, model_classes, task, framework, **model_kwargs)[0m
[1;32m    208[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[1;32m    209[0m [38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).[39;00m
[1;32m    210[0m 
[0;32m   (...)[0m
[1;32m    231[0m [38;5;124;03m    `Tuple`: A tuple framework, model.[39;00m
[1;32m    232[0m [38;5;124;03m"""[39;00m
[1;32m    233[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m is_tf_available() [38;5;129;01mand[39;00m [38;5;129;01mnot[39;00m is_torch_available():
[0;32m--> 234[0m     [38;5;28;01mraise[39;00m [38;5;167;01mRuntimeError[39;00m(
[1;32m    235[0m         [38;5;124m"[39m[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. [39m[38;5;124m"[39m
[1;32m    236[0m         [38;5;124m"[39m[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ [39m[38;5;124m"[39m
[1;32m    237[0m         [38;5;124m"[39m[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.[39m[38;5;124m"[39m
[1;32m    238[0m     )
[1;32m    239[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(model, [38;5;28mstr[39m):
[1;32m    240[0m     model_kwargs[[38;5;124m"[39m[38;5;124m_from_pipeline[39m[38;5;124m"[39m] [38;5;241m=[39m task

[0;31mRuntimeError[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.

